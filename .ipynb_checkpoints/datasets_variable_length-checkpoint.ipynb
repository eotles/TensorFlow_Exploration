{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "try:\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset example\n",
    "With lambda functions, zipping, shuffling, and padding\n",
    "\n",
    "Make a vector y with values, x will be an array of ones of length equal to y.\n",
    "The RNN should learn how to count the ones to get y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_y = tf.data.Dataset.range(50)\n",
    "ds_x = ds_y.map(lambda x: tf.fill([tf.cast(x, tf.int32)], 1.0))\n",
    "ds_x = ds_x.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "ds = tf.data.Dataset.zip((ds_x, ds_y))\n",
    "ds = ds.shuffle(buffer_size=100)\n",
    "\n",
    "ds = ds.padded_batch(32, padded_shapes=([None, None], ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(units = 16, activation='relu'),\n",
    "    tf.keras.layers.Dense(8),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanSquaredError(), \n",
    "              metrics=['MAE', 'MSE' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "2/2 [==============================] - 1s 437ms/step - loss: 814.3734 - MAE: 24.4442 - MSE: 803.4174\n",
      "Epoch 2/250\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 749.6714 - MAE: 24.4271 - MSE: 802.4827\n",
      "Epoch 3/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 824.2189 - MAE: 24.3985 - MSE: 800.6992\n",
      "Epoch 4/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 802.9745 - MAE: 24.3869 - MSE: 800.3390\n",
      "Epoch 5/250\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 760.0830 - MAE: 24.3555 - MSE: 798.4247\n",
      "Epoch 6/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 813.2259 - MAE: 24.3324 - MSE: 797.3296\n",
      "Epoch 7/250\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 803.2166 - MAE: 24.2814 - MSE: 793.8385\n",
      "Epoch 8/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 802.3698 - MAE: 24.2599 - MSE: 792.9238\n",
      "Epoch 9/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 736.4610 - MAE: 24.2032 - MSE: 789.1817\n",
      "Epoch 10/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 739.6738 - MAE: 24.1741 - MSE: 787.8575\n",
      "Epoch 11/250\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 743.5054 - MAE: 24.1103 - MSE: 783.8876\n",
      "Epoch 12/250\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 731.3530 - MAE: 24.0263 - MSE: 778.2709\n",
      "Epoch 13/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 830.3640 - MAE: 23.9988 - MSE: 777.8444\n",
      "Epoch 14/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 769.7694 - MAE: 23.9148 - MSE: 772.7586\n",
      "Epoch 15/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 784.5217 - MAE: 23.8017 - MSE: 765.6205\n",
      "Epoch 16/250\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 768.3051 - MAE: 23.6894 - MSE: 759.0162\n",
      "Epoch 17/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 795.0430 - MAE: 23.5309 - MSE: 749.5912\n",
      "Epoch 18/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 728.1135 - MAE: 23.4373 - MSE: 745.5086\n",
      "Epoch 19/250\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 756.8783 - MAE: 23.1511 - MSE: 727.3461\n",
      "Epoch 20/250\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 750.4782 - MAE: 23.0549 - MSE: 725.2263\n",
      "Epoch 21/250\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 639.2145 - MAE: 22.7295 - MSE: 706.3367\n",
      "Epoch 22/250\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 681.3810 - MAE: 22.3371 - MSE: 685.3840\n",
      "Epoch 23/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 701.5715 - MAE: 21.7544 - MSE: 655.3175\n",
      "Epoch 24/250\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 610.1262 - MAE: 20.7641 - MSE: 602.1248\n",
      "Epoch 25/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 514.6877 - MAE: 19.3066 - MSE: 527.0207\n",
      "Epoch 26/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 417.0057 - MAE: 16.7431 - MSE: 406.1179\n",
      "Epoch 27/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 261.6291 - MAE: 12.7629 - MSE: 237.6275\n",
      "Epoch 28/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 95.5751 - MAE: 8.7974 - MSE: 105.3777\n",
      "Epoch 29/250\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 300.3378 - MAE: 15.4112 - MSE: 284.5565\n",
      "Epoch 30/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 140.1707 - MAE: 9.4700 - MSE: 128.3285\n",
      "Epoch 31/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 83.3168 - MAE: 7.9566 - MSE: 87.9841\n",
      "Epoch 32/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 119.5984 - MAE: 9.6809 - MSE: 134.3816\n",
      "Epoch 33/250\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 152.8121 - MAE: 10.3507 - MSE: 155.8177\n",
      "Epoch 34/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 144.1525 - MAE: 10.1407 - MSE: 148.6239\n",
      "Epoch 35/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 126.2297 - MAE: 9.1952 - MSE: 120.5759\n",
      "Epoch 36/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 83.6140 - MAE: 7.7934 - MSE: 82.0924\n",
      "Epoch 37/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 67.2703 - MAE: 7.3219 - MSE: 73.5655\n",
      "Epoch 38/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 89.3557 - MAE: 7.9234 - MSE: 88.6247\n",
      "Epoch 39/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 89.8312 - MAE: 7.9802 - MSE: 89.0565\n",
      "Epoch 40/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 81.5291 - MAE: 7.4202 - MSE: 74.5792\n",
      "Epoch 41/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 59.9132 - MAE: 6.8347 - MSE: 62.0496\n",
      "Epoch 42/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 65.7599 - MAE: 7.0353 - MSE: 65.1531\n",
      "Epoch 43/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 70.8067 - MAE: 7.1187 - MSE: 67.9952\n",
      "Epoch 44/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 66.2478 - MAE: 6.9398 - MSE: 63.6974\n",
      "Epoch 45/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 57.3048 - MAE: 6.4784 - MSE: 55.4079\n",
      "Epoch 46/250\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 49.3117 - MAE: 6.2178 - MSE: 51.7804\n",
      "Epoch 47/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 49.2916 - MAE: 5.9688 - MSE: 47.4539\n",
      "Epoch 48/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 52.7830 - MAE: 6.1427 - MSE: 51.4713\n",
      "Epoch 49/250\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 42.6876 - MAE: 5.9121 - MSE: 48.0426\n",
      "Epoch 50/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 43.7414 - MAE: 5.7506 - MSE: 43.9355\n",
      "Epoch 51/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 40.1927 - MAE: 5.6691 - MSE: 43.1139\n",
      "Epoch 52/250\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 44.3717 - MAE: 5.5871 - MSE: 41.7434\n",
      "Epoch 53/250\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 34.2235 - MAE: 5.3278 - MSE: 38.3559\n",
      "Epoch 54/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 38.1572 - MAE: 5.0802 - MSE: 35.1828\n",
      "Epoch 55/250\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 36.1236 - MAE: 4.7804 - MSE: 32.4505\n",
      "Epoch 56/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 26.7954 - MAE: 4.5749 - MSE: 30.2829\n",
      "Epoch 57/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 29.3234 - MAE: 4.3683 - MSE: 27.7978\n",
      "Epoch 58/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 21.3088 - MAE: 3.9419 - MSE: 23.0244\n",
      "Epoch 59/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 20.2784 - MAE: 3.8026 - MSE: 21.0486\n",
      "Epoch 60/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 16.4080 - MAE: 3.5713 - MSE: 18.6449\n",
      "Epoch 61/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 16.7557 - MAE: 3.1767 - MSE: 16.3384\n",
      "Epoch 62/250\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 15.9264 - MAE: 2.9248 - MSE: 15.0449\n",
      "Epoch 63/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 15.1064 - MAE: 2.8930 - MSE: 15.7808\n",
      "Epoch 64/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 15.0491 - MAE: 2.7567 - MSE: 14.6272\n",
      "Epoch 65/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 13.2082 - MAE: 2.6240 - MSE: 13.1714\n",
      "Epoch 66/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 14.1271 - MAE: 3.1913 - MSE: 14.8001\n",
      "Epoch 67/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 15.4300 - MAE: 3.1861 - MSE: 14.5163\n",
      "Epoch 68/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 14.1164 - MAE: 2.8169 - MSE: 13.1884\n",
      "Epoch 69/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 12.7191 - MAE: 2.4694 - MSE: 12.6522\n",
      "Epoch 70/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 13.6902 - MAE: 2.2679 - MSE: 12.2258\n",
      "Epoch 71/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 11.6164 - MAE: 2.4222 - MSE: 11.3199\n",
      "Epoch 72/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 9.9753 - MAE: 2.3136 - MSE: 9.8495\n",
      "Epoch 73/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 8.0643 - MAE: 2.3042 - MSE: 9.3691\n",
      "Epoch 74/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 26ms/step - loss: 10.6634 - MAE: 2.4478 - MSE: 9.9009\n",
      "Epoch 75/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 9.9464 - MAE: 2.1047 - MSE: 8.8830\n",
      "Epoch 76/250\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 7.2520 - MAE: 1.9945 - MSE: 8.5649\n",
      "Epoch 77/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 7.7578 - MAE: 1.9132 - MSE: 8.0558\n",
      "Epoch 78/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 8.3957 - MAE: 1.9080 - MSE: 7.2680\n",
      "Epoch 79/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 8.2016 - MAE: 2.1850 - MSE: 7.5052\n",
      "Epoch 80/250\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 6.6361 - MAE: 1.9478 - MSE: 6.4731\n",
      "Epoch 81/250\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 5.3459 - MAE: 1.6989 - MSE: 5.4451\n",
      "Epoch 82/250\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 5.0951 - MAE: 1.5328 - MSE: 4.4771\n",
      "Epoch 83/250\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 2.4655 - MAE: 1.3353 - MSE: 2.7045\n",
      "Epoch 84/250\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 3.2663 - MAE: 1.4313 - MSE: 2.9871\n",
      "Epoch 85/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 1.1836 - MAE: 1.0409 - MSE: 1.7246\n",
      "Epoch 86/250\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.7216 - MAE: 0.8225 - MSE: 1.4953\n",
      "Epoch 87/250\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.8674 - MAE: 0.6888 - MSE: 0.9328\n",
      "Epoch 88/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 1.1280 - MAE: 0.8628 - MSE: 1.2854\n",
      "Epoch 89/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7026 - MAE: 0.7162 - MSE: 0.7557\n",
      "Epoch 90/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5382 - MAE: 0.5548 - MSE: 0.5698\n",
      "Epoch 91/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6981 - MAE: 0.7234 - MSE: 0.8752\n",
      "Epoch 92/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7362 - MAE: 0.6164 - MSE: 0.6753\n",
      "Epoch 93/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5444 - MAE: 0.6624 - MSE: 0.6538\n",
      "Epoch 94/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5057 - MAE: 0.5721 - MSE: 0.5046\n",
      "Epoch 95/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2904 - MAE: 0.4464 - MSE: 0.2895\n",
      "Epoch 96/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3209 - MAE: 0.4769 - MSE: 0.3714\n",
      "Epoch 97/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3648 - MAE: 0.4808 - MSE: 0.3754\n",
      "Epoch 98/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4734 - MAE: 0.6137 - MSE: 0.5270\n",
      "Epoch 99/250\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6062 - MAE: 0.7198 - MSE: 0.7769\n",
      "Epoch 100/250\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5698 - MAE: 0.6455 - MSE: 0.6691\n",
      "Epoch 101/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7507 - MAE: 0.7635 - MSE: 0.9153\n",
      "Epoch 102/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7634 - MAE: 0.7063 - MSE: 0.7398\n",
      "Epoch 103/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 1.1067 - MAE: 0.9821 - MSE: 1.8081\n",
      "Epoch 104/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4547 - MAE: 0.5597 - MSE: 0.4403\n",
      "Epoch 105/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6199 - MAE: 0.6144 - MSE: 0.5651\n",
      "Epoch 106/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4111 - MAE: 0.5492 - MSE: 0.4202\n",
      "Epoch 107/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.9728 - MAE: 0.7594 - MSE: 0.8285\n",
      "Epoch 108/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3057 - MAE: 0.4469 - MSE: 0.2930\n",
      "Epoch 109/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3249 - MAE: 0.5148 - MSE: 0.3671\n",
      "Epoch 110/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5163 - MAE: 0.6736 - MSE: 0.6901\n",
      "Epoch 111/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2332 - MAE: 0.4147 - MSE: 0.2479\n",
      "Epoch 112/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4051 - MAE: 0.5830 - MSE: 0.4694\n",
      "Epoch 113/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3366 - MAE: 0.5347 - MSE: 0.4681\n",
      "Epoch 114/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5192 - MAE: 0.5813 - MSE: 0.5074\n",
      "Epoch 115/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3701 - MAE: 0.4796 - MSE: 0.3578\n",
      "Epoch 116/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3547 - MAE: 0.4882 - MSE: 0.3939\n",
      "Epoch 117/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2780 - MAE: 0.4025 - MSE: 0.2579\n",
      "Epoch 118/250\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2977 - MAE: 0.4203 - MSE: 0.3025\n",
      "Epoch 119/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.4484 - MAE: 0.5280 - MSE: 0.4280\n",
      "Epoch 120/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2472 - MAE: 0.4144 - MSE: 0.2397\n",
      "Epoch 121/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2185 - MAE: 0.3650 - MSE: 0.2079\n",
      "Epoch 122/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1972 - MAE: 0.3697 - MSE: 0.2047\n",
      "Epoch 123/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2245 - MAE: 0.3905 - MSE: 0.2303\n",
      "Epoch 124/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1799 - MAE: 0.3723 - MSE: 0.2029\n",
      "Epoch 125/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1889 - MAE: 0.3544 - MSE: 0.1796\n",
      "Epoch 126/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2052 - MAE: 0.3813 - MSE: 0.2253\n",
      "Epoch 127/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3061 - MAE: 0.4137 - MSE: 0.2942\n",
      "Epoch 128/250\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.2035 - MAE: 0.3920 - MSE: 0.2192\n",
      "Epoch 129/250\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2801 - MAE: 0.4398 - MSE: 0.3337\n",
      "Epoch 130/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1629 - MAE: 0.3539 - MSE: 0.1793\n",
      "Epoch 131/250\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2048 - MAE: 0.3367 - MSE: 0.1834\n",
      "Epoch 132/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1968 - MAE: 0.3576 - MSE: 0.1903\n",
      "Epoch 133/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1895 - MAE: 0.3554 - MSE: 0.1954\n",
      "Epoch 134/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2022 - MAE: 0.3795 - MSE: 0.2182\n",
      "Epoch 135/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2019 - MAE: 0.3761 - MSE: 0.2000\n",
      "Epoch 136/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1816 - MAE: 0.3495 - MSE: 0.1677\n",
      "Epoch 137/250\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1893 - MAE: 0.3451 - MSE: 0.1843\n",
      "Epoch 138/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1988 - MAE: 0.3148 - MSE: 0.1799\n",
      "Epoch 139/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4036 - MAE: 0.5277 - MSE: 0.6086\n",
      "Epoch 140/250\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1985 - MAE: 0.3861 - MSE: 0.2028\n",
      "Epoch 141/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3087 - MAE: 0.4129 - MSE: 0.2866\n",
      "Epoch 142/250\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2747 - MAE: 0.3635 - MSE: 0.2636\n",
      "Epoch 143/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3037 - MAE: 0.4046 - MSE: 0.3085\n",
      "Epoch 144/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2248 - MAE: 0.3636 - MSE: 0.2251\n",
      "Epoch 145/250\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2590 - MAE: 0.3617 - MSE: 0.2409\n",
      "Epoch 146/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1850 - MAE: 0.3631 - MSE: 0.1836\n",
      "Epoch 147/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3359 - MAE: 0.5193 - MSE: 0.4787\n",
      "Epoch 148/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3158 - MAE: 0.4286 - MSE: 0.2744\n",
      "Epoch 149/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1958 - MAE: 0.3890 - MSE: 0.2079\n",
      "Epoch 150/250\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3915 - MAE: 0.5272 - MSE: 0.6030\n",
      "Epoch 151/250\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2286 - MAE: 0.3578 - MSE: 0.2226\n",
      "Epoch 152/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2291 - MAE: 0.3899 - MSE: 0.2395\n",
      "Epoch 153/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3627 - MAE: 0.4439 - MSE: 0.3096\n",
      "Epoch 154/250\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1825 - MAE: 0.3484 - MSE: 0.1877\n",
      "Epoch 155/250\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3574 - MAE: 0.5360 - MSE: 0.4749\n",
      "Epoch 156/250\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2199 - MAE: 0.4320 - MSE: 0.3173\n",
      "Epoch 157/250\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4416 - MAE: 0.4477 - MSE: 0.3646\n",
      "Epoch 158/250\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1510 - MAE: 0.3473 - MSE: 0.1848\n",
      "Epoch 159/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1505 - MAE: 0.3024 - MSE: 0.1554\n",
      "Epoch 160/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1375 - MAE: 0.2796 - MSE: 0.1490\n",
      "Epoch 161/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2901 - MAE: 0.4148 - MSE: 0.3014\n",
      "Epoch 162/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2881 - MAE: 0.4099 - MSE: 0.2458\n",
      "Epoch 163/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1335 - MAE: 0.2848 - MSE: 0.1445\n",
      "Epoch 164/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2834 - MAE: 0.4710 - MSE: 0.3889\n",
      "Epoch 165/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1932 - MAE: 0.3846 - MSE: 0.2414\n",
      "Epoch 166/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3442 - MAE: 0.3811 - MSE: 0.2799\n",
      "Epoch 167/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1614 - MAE: 0.3370 - MSE: 0.1932\n",
      "Epoch 168/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1868 - MAE: 0.3678 - MSE: 0.1882\n",
      "Epoch 169/250\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1213 - MAE: 0.2773 - MSE: 0.1165\n",
      "Epoch 170/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1305 - MAE: 0.2926 - MSE: 0.1604\n",
      "Epoch 171/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1730 - MAE: 0.3240 - MSE: 0.1964\n",
      "Epoch 172/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1061 - MAE: 0.2422 - MSE: 0.1037\n",
      "Epoch 173/250\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1083 - MAE: 0.2384 - MSE: 0.1039\n",
      "Epoch 174/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0950 - MAE: 0.2401 - MSE: 0.0967\n",
      "Epoch 175/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1107 - MAE: 0.2579 - MSE: 0.1206\n",
      "Epoch 176/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1355 - MAE: 0.2902 - MSE: 0.1799\n",
      "Epoch 177/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1786 - MAE: 0.3024 - MSE: 0.1857\n",
      "Epoch 178/250\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.1592 - MAE: 0.2934 - MSE: 0.1446\n",
      "Epoch 179/250\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2397 - MAE: 0.3088 - MSE: 0.2091\n",
      "Epoch 180/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1405 - MAE: 0.2611 - MSE: 0.1422\n",
      "Epoch 181/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1181 - MAE: 0.2428 - MSE: 0.0992\n",
      "Epoch 182/250\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1187 - MAE: 0.2454 - MSE: 0.1212\n",
      "Epoch 183/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0896 - MAE: 0.2219 - MSE: 0.0915\n",
      "Epoch 184/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0904 - MAE: 0.2143 - MSE: 0.1055\n",
      "Epoch 185/250\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.1054 - MAE: 0.2429 - MSE: 0.1106\n",
      "Epoch 186/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1183 - MAE: 0.2622 - MSE: 0.1195\n",
      "Epoch 187/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1271 - MAE: 0.2374 - MSE: 0.1159\n",
      "Epoch 188/250\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0846 - MAE: 0.2202 - MSE: 0.0912\n",
      "Epoch 189/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0874 - MAE: 0.2177 - MSE: 0.0919\n",
      "Epoch 190/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1740 - MAE: 0.3186 - MSE: 0.1904\n",
      "Epoch 191/250\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1559 - MAE: 0.3165 - MSE: 0.1629\n",
      "Epoch 192/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1397 - MAE: 0.3069 - MSE: 0.1754\n",
      "Epoch 193/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1919 - MAE: 0.3362 - MSE: 0.1873\n",
      "Epoch 194/250\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1171 - MAE: 0.2489 - MSE: 0.1158\n",
      "Epoch 195/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1294 - MAE: 0.2655 - MSE: 0.1401\n",
      "Epoch 196/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1646 - MAE: 0.2540 - MSE: 0.1591\n",
      "Epoch 197/250\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1027 - MAE: 0.2516 - MSE: 0.1083\n",
      "Epoch 198/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0665 - MAE: 0.2072 - MSE: 0.0751\n",
      "Epoch 199/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1980 - MAE: 0.3756 - MSE: 0.2579\n",
      "Epoch 200/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0985 - MAE: 0.2178 - MSE: 0.0994\n",
      "Epoch 201/250\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.1569 - MAE: 0.3557 - MSE: 0.1853\n",
      "Epoch 202/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1591 - MAE: 0.3111 - MSE: 0.1887\n",
      "Epoch 203/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2001 - MAE: 0.3541 - MSE: 0.1825\n",
      "Epoch 204/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1206 - MAE: 0.2468 - MSE: 0.1216\n",
      "Epoch 205/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1600 - MAE: 0.2967 - MSE: 0.1780\n",
      "Epoch 206/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1793 - MAE: 0.2811 - MSE: 0.1612\n",
      "Epoch 207/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1993 - MAE: 0.3789 - MSE: 0.2975\n",
      "Epoch 208/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0938 - MAE: 0.2481 - MSE: 0.1138\n",
      "Epoch 209/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1382 - MAE: 0.2514 - MSE: 0.1281\n",
      "Epoch 210/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0927 - MAE: 0.2355 - MSE: 0.1053\n",
      "Epoch 211/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1569 - MAE: 0.2705 - MSE: 0.1444\n",
      "Epoch 212/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0894 - MAE: 0.2255 - MSE: 0.0967\n",
      "Epoch 213/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0715 - MAE: 0.1994 - MSE: 0.0757\n",
      "Epoch 214/250\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0819 - MAE: 0.2155 - MSE: 0.0997\n",
      "Epoch 215/250\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1104 - MAE: 0.2068 - MSE: 0.1108\n",
      "Epoch 216/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1401 - MAE: 0.2877 - MSE: 0.1677\n",
      "Epoch 217/250\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0947 - MAE: 0.2295 - MSE: 0.1045\n",
      "Epoch 218/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0832 - MAE: 0.2180 - MSE: 0.0969\n",
      "Epoch 219/250\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0791 - MAE: 0.2041 - MSE: 0.0748\n",
      "Epoch 220/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0968 - MAE: 0.2296 - MSE: 0.0929\n",
      "Epoch 221/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0837 - MAE: 0.2171 - MSE: 0.0959\n",
      "Epoch 222/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0825 - MAE: 0.2012 - MSE: 0.0882\n",
      "Epoch 223/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0885 - MAE: 0.2149 - MSE: 0.1105\n",
      "Epoch 224/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0816 - MAE: 0.1966 - MSE: 0.0836\n",
      "Epoch 225/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0963 - MAE: 0.2072 - MSE: 0.0944\n",
      "Epoch 226/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1130 - MAE: 0.2481 - MSE: 0.1534\n",
      "Epoch 227/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0743 - MAE: 0.2110 - MSE: 0.0907\n",
      "Epoch 228/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0813 - MAE: 0.2017 - MSE: 0.0829\n",
      "Epoch 229/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0956 - MAE: 0.2523 - MSE: 0.0987\n",
      "Epoch 230/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2813 - MAE: 0.4127 - MSE: 0.4687\n",
      "Epoch 231/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2346 - MAE: 0.4362 - MSE: 0.2895\n",
      "Epoch 232/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1849 - MAE: 0.3295 - MSE: 0.2283\n",
      "Epoch 233/250\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1177 - MAE: 0.3026 - MSE: 0.1152\n",
      "Epoch 234/250\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1061 - MAE: 0.2485 - MSE: 0.1249\n",
      "Epoch 235/250\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0757 - MAE: 0.2265 - MSE: 0.0901\n",
      "Epoch 236/250\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2201 - MAE: 0.3624 - MSE: 0.3505\n",
      "Epoch 237/250\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1498 - MAE: 0.2752 - MSE: 0.1560\n",
      "Epoch 238/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2753 - MAE: 0.4419 - MSE: 0.3430\n",
      "Epoch 239/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0815 - MAE: 0.1882 - MSE: 0.0729\n",
      "Epoch 240/250\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0984 - MAE: 0.2469 - MSE: 0.0987\n",
      "Epoch 241/250\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1362 - MAE: 0.2515 - MSE: 0.1417\n",
      "Epoch 242/250\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1036 - MAE: 0.2084 - MSE: 0.0944\n",
      "Epoch 243/250\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1050 - MAE: 0.2547 - MSE: 0.1271\n",
      "Epoch 244/250\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1476 - MAE: 0.3056 - MSE: 0.2161\n",
      "Epoch 245/250\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1498 - MAE: 0.3400 - MSE: 0.1694\n",
      "Epoch 246/250\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0925 - MAE: 0.2443 - MSE: 0.0978\n",
      "Epoch 247/250\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2037 - MAE: 0.3648 - MSE: 0.2377\n",
      "Epoch 248/250\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1099 - MAE: 0.2707 - MSE: 0.1160\n",
      "Epoch 249/250\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2080 - MAE: 0.3334 - MSE: 0.2144\n",
      "Epoch 250/250\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0935 - MAE: 0.2567 - MSE: 0.0926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7483eedb70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       multiple                  288       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  136       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  9         \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22 35 40 20 34  6 32  3 15  5 37 41 14 12  8 16 36 48 24 25 49 19 21 31\n",
      "  4 29  0 44 26 39  2 13]\n"
     ]
    }
   ],
   "source": [
    "for b in ds.take(1):\n",
    "    b_x, b_y = b\n",
    "    #print(b_x.numpy())\n",
    "    print(b_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.301 35.168 39.702 20.352 34.244  6.207 32.31   3.485 15.373  5.302\n",
      " 36.976 40.702 14.416 12.559  8.219 16.283 36.079 48.053 24.238 25.239\n",
      " 48.239 19.337 21.339 31.298  4.453 29.28   0.622 44.215 26.244 38.765\n",
      "  2.271 13.482]\n"
     ]
    }
   ],
   "source": [
    "b_y_hat = model.predict(b_x)\n",
    "print(np.squeeze(b_y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expand this approach to having named arrays.\n",
    "\n",
    "The goal will be for the model to learn how to do weighted counting of two different arrays. <br>\n",
    "For inputs: we will use two copies of x (x_1 and x_2). <br>\n",
    "Output: y = 1\\*y_1 + 2\\*y_2, where y_i = len(x_i). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "\n",
    "ds_y_1 = tf.data.Dataset.from_tensor_slices(np.random.randint(0, 100, size=n))   \n",
    "ds_y_2 = tf.data.Dataset.from_tensor_slices(np.random.randint(0, 100, size=n))\n",
    "\n",
    "ds_x_1 = ds_y_1.map(lambda x: tf.fill([tf.cast(x, tf.int32)], 1.0))\n",
    "ds_x_1 = ds_x_1.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "ds_x_2 = ds_y_2.map(lambda x: tf.fill([tf.cast(x, tf.int32)], 1.0))\n",
    "ds_x_2 = ds_x_2.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "ds_y = tf.data.Dataset.zip((ds_y_1, ds_y_2))\n",
    "ds_y = ds_y.map(lambda y_1, y_2: y_1 + 2*y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.zip((ds_x_1, ds_x_2, ds_y))\n",
    "#ds = ds.map(lambda x_1, x_2, y: {'x_1': x_1, 'x_2': x_2, 'y': y})\n",
    "ds = ds.map(lambda x_1, x_2, y: ({'x_1': x_1, 'x_2': x_2}, y))\n",
    "\n",
    "ds = ds.shuffle(buffer_size=100)\n",
    "#ds = ds.padded_batch(32, padded_shapes={'x_1': [None, None], 'x_2':[None, None], 'y':()})\n",
    "ds = ds.padded_batch(32, padded_shapes=({'x_1': [None, None], 'x_2':[None, None]}, ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'x_1': <tf.Tensor: id=6235, shape=(32, 95, 1), dtype=float32, numpy=\n",
      "array([[[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]], dtype=float32)>, 'x_2': <tf.Tensor: id=6236, shape=(32, 99, 1), dtype=float32, numpy=\n",
      "array([[[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]],\n",
      "\n",
      "       [[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]], dtype=float32)>}, <tf.Tensor: id=6237, shape=(32,), dtype=int64, numpy=\n",
      "array([197, 163, 144, 126, 253, 114, 152, 155, 170, 203, 276,  80, 117,\n",
      "       138,  39,  94, 281, 219, 130,  78, 135,  38, 203,  33, 230, 241,\n",
      "       275,  69, 240, 149, 217,  80])>)\n"
     ]
    }
   ],
   "source": [
    "it = iter(ds)\n",
    "z = next(it)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 95, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0]['x_1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 99, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0]['x_2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1_input_layer = tf.keras.layers.Input(shape=(None, 1, ), name='x_1')\n",
    "x_2_input_layer = tf.keras.layers.Input(shape=(None, 1, ), name='x_2')\n",
    "#y = tf.keras.layers.Input(shape=(None,), name='y')\n",
    "\n",
    "rnn_1 = tf.keras.layers.SimpleRNN(units= 16, activation='relu')(x_1_input_layer)\n",
    "rnn_2 = tf.keras.layers.SimpleRNN(units= 16, activation='relu')(x_2_input_layer)\n",
    "\n",
    "merge = tf.keras.layers.concatenate([rnn_1, rnn_2])\n",
    "\n",
    "dense_1 = tf.keras.layers.Dense(8)(merge)\n",
    "dense_2 = tf.keras.layers.Dense(1)(dense_1)\n",
    "\n",
    "model = tf.keras.Model(inputs = {'x_1': x_1_input_layer, 'x_2': x_2_input_layer}, outputs=dense_2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanSquaredError(), \n",
    "              metrics=['MAE', 'MSE' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x_1 (InputLayer)                [(None, None, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "x_2 (InputLayer)                [(None, None, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)        (None, 16)           288         x_1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)        (None, 16)           288         x_2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32)           0           simple_rnn_1[0][0]               \n",
      "                                                                 simple_rnn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            264         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            9           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 849\n",
      "Trainable params: 849\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 22s 70ms/step - loss: 4503.7629 - MAE: 39.9882 - MSE: 4510.8398\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 48.5524 - MAE: 5.3781 - MSE: 48.5351\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 24.1671 - MAE: 3.6708 - MSE: 24.1591\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 10.4525 - MAE: 2.3574 - MSE: 10.4392\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 17s 55ms/step - loss: 4.5090 - MAE: 1.6481 - MSE: 4.5435\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 18s 58ms/step - loss: 4.1874 - MAE: 1.5034 - MSE: 4.1939\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 2.9065 - MAE: 1.2892 - MSE: 2.9028\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 3.3897 - MAE: 1.4258 - MSE: 3.3861\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 20s 65ms/step - loss: 2.3400 - MAE: 1.1711 - MSE: 2.3387\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 19s 59ms/step - loss: 2.5134 - MAE: 1.2184 - MSE: 2.5104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f742c5e2c88>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 90  43 253 219 158 191  66 132  80 133 181 241 146 190 114 160 189  95\n",
      " 224 138  94 126 160  82  38   6  90 131 260 253  77 275]\n"
     ]
    }
   ],
   "source": [
    "for b in ds.take(1):\n",
    "    b_x, b_y = b\n",
    "    #print(b_x.numpy())\n",
    "    print(b_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 90.839  42.862 253.671 220.331 159.043 192.072  66.361 133.158  80.979\n",
      " 133.847 182.102 241.629 146.906 191.343 115.039 161.029 189.983  93.982\n",
      " 224.154 138.791  94.628 127.121 161.049  82.36   38.25    8.253  92.215\n",
      " 131.552 260.55  254.476  77.062 276.068]\n"
     ]
    }
   ],
   "source": [
    "b_y_hat = model.predict(b_x)\n",
    "print(np.squeeze(b_y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1_input_layer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_1(x_1_input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(units = 16, activation='relu'),\n",
    "    tf.keras.layers.Dense(8),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanSquaredError(), \n",
    "              metrics=['MAE', 'MSE' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_y.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(b_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "y = np.tile(np.arange(1, 11), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vec(x_batch):\n",
    "    #get max length\n",
    "    batch_size = len(x_batch)\n",
    "    seq_len = np.max(x_batch)+1\n",
    "    arr = np.zeros(shape=(batch_size, seq_len))\n",
    "    arr[np.arange(batch_size), x_batch] = -1\n",
    "    arr = np.cumsum(arr, axis=1) + 1\n",
    "    arr = np.expand_dims(arr, -1)\n",
    "    return(arr)\n",
    "\n",
    "def tf_make_vec(x_batch, y):\n",
    "    [x, ] = tf.py_function(make_vec, [x_batch], [tf.float32])\n",
    "    #x.set_shape(im_shape)\n",
    "    return(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_vec(y[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_ds = tf.data.Dataset.from_tensor_slices(y)\n",
    "y_ds = tf.data.Dataset.from_tensor_slices(y)\n",
    "dataset = tf.data.Dataset.zip((x_ds, y_ds))\n",
    "#dataset = tf.data.Dataset.from_tensor_slices((y, y))\n",
    "dataset = dataset.shuffle(buffer_size=100)\n",
    "dataset = dataset.batch(4, drop_remainder=True)\n",
    "\n",
    "for batch in dataset.take(2):\n",
    "    print([arr.numpy() for arr in batch])\n",
    "\n",
    "    \n",
    "dataset = dataset.map(tf_make_vec)\n",
    "\n",
    "for _x, _y in dataset.take(2):\n",
    "    #print(_x.numpy(), '\\n' ,_y.numpy())\n",
    "    print(_x, _y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _x, _y in dataset:\n",
    "    #print(_x.numpy(), '\\n' ,_y.numpy())\n",
    "    print(_x, _y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for b in ds.take(200):\n",
    "    b_x, b_y = b\n",
    "    print(b_x.shape)\n",
    "    print(b_y.shape)\n",
    "    #print(b_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.range(100)\n",
    "dataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], 1))\n",
    "dataset = dataset.map(lambda x: tf.expand_dims(x, -1))\n",
    "dataset = dataset.padded_batch(4, padded_shapes=(None, 1))\n",
    "\n",
    "for batch in dataset.take(2):\n",
    "    print(batch.numpy())\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batched_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = tf.data.Dataset.from_tensor_slices(y)\n",
    "#dataset = dataset.shuffle(buffer_size=100)\n",
    "#dataset = dataset.batch(5)\n",
    "\n",
    "#for batch in dataset.take(4):\n",
    "#    print([arr.numpy() for arr in batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "images, labels = train\n",
    "images = images/255.0\n",
    "labels = labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmnist_train_ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "fmnist_train_ds = fmnist_train_ds.shuffle(5000).batch(32)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(fmnist_train_ds, epochs=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
